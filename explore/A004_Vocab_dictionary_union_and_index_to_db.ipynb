{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# indexing the rhyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/personal_working/bavandangvanba/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "PRJ_BASE ='/mnt/d/personal_working/bavandangvanba'\n",
    "base_path = PRJ_BASE\n",
    "sys.path.append(base_path)\n",
    "from core.utils import (\n",
    "    vn_grammar_handler,\n",
    "    db_handler,\n",
    "    init_logger)\n",
    "init_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "n_gram_phrases_song = pd.read_pickle(os.path.join(PRJ_BASE,'tmp/dictionary_from_songs_data.pkl'))\n",
    "n_gram_phrases_truyen = pd.read_pickle(os.path.join(PRJ_BASE,'tmp/dictionary_from_truyen_data.pkl'))\n",
    "n_gram_phrases = n_gram_phrases_truyen\n",
    "for key,count in n_gram_phrases_song.items():\n",
    "    if key not in n_gram_phrases:\n",
    "        n_gram_phrases[key] = count*10\n",
    "    else:\n",
    "        n_gram_phrases[key] += count*10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1514931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n_gram_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_data = []\n",
    "van_indexing = {} \n",
    "for idx,(word, count) in enumerate(n_gram_phrases.items()):\n",
    "    cleaned_text = vn_grammar_handler.bo_dau_va_chuyen_van(word)\n",
    "    matches_01 = vn_grammar_handler.lay_van_cua_tu_hoac_doan(cleaned_text)\n",
    "    matches_02 = vn_grammar_handler.clean_phu_am(cleaned_text)\n",
    "    if matches_01!=matches_02:\n",
    "        wrong_data.append(['something wrong', word, matches_01, matches_02])\n",
    "    if matches_01 not in van_indexing:\n",
    "        van_indexing[matches_01] = []\n",
    "    van_indexing[matches_01].append((word,count))\n",
    "for van in van_indexing:\n",
    "    van_indexing[van].sort(key=lambda x:x[1],reverse=True)\n",
    "del van_indexing[\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7ff28607afc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(os.path.join(PRJ_BASE,'app_metadata/example.db'))\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a table if it doesn't exist\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS van_indexing\n",
    "                  (id TEXT PRIMARY KEY, words TEXT)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 05:04:09 INFO       - processed 0 van\n",
      "2023-11-11 05:04:09 INFO       - processed 10000 van\n",
      "2023-11-11 05:04:10 INFO       - processed 20000 van\n",
      "2023-11-11 05:04:10 INFO       - processed 30000 van\n",
      "2023-11-11 05:04:10 INFO       - processed 40000 van\n",
      "2023-11-11 05:04:10 INFO       - processed 50000 van\n",
      "2023-11-11 05:04:10 INFO       - processed 60000 van\n",
      "2023-11-11 05:04:10 INFO       - processed 70000 van\n",
      "2023-11-11 05:04:10 INFO       - processed 80000 van\n",
      "2023-11-11 05:04:10 INFO       - processed 90000 van\n",
      "2023-11-11 05:04:11 INFO       - processed 100000 van\n",
      "2023-11-11 05:04:11 INFO       - processed 110000 van\n",
      "2023-11-11 05:04:12 INFO       - processed 120000 van\n",
      "2023-11-11 05:04:12 INFO       - processed 130000 van\n",
      "2023-11-11 05:04:13 INFO       - processed 140000 van\n",
      "2023-11-11 05:04:14 INFO       - processed 150000 van\n",
      "2023-11-11 05:04:15 INFO       - processed 160000 van\n",
      "2023-11-11 05:04:16 INFO       - processed 170000 van\n",
      "2023-11-11 05:04:17 INFO       - processed 180000 van\n",
      "2023-11-11 05:04:18 INFO       - processed 190000 van\n",
      "2023-11-11 05:04:20 INFO       - processed 200000 van\n",
      "2023-11-11 05:04:21 INFO       - processed 210000 van\n",
      "2023-11-11 05:04:22 INFO       - processed 220000 van\n",
      "2023-11-11 05:04:24 INFO       - processed 230000 van\n",
      "2023-11-11 05:04:25 INFO       - processed 240000 van\n",
      "2023-11-11 05:04:27 INFO       - processed 250000 van\n",
      "2023-11-11 05:04:29 INFO       - processed 260000 van\n",
      "2023-11-11 05:04:30 INFO       - processed 270000 van\n",
      "2023-11-11 05:04:32 INFO       - processed 280000 van\n",
      "2023-11-11 05:04:33 INFO       - processed 290000 van\n",
      "2023-11-11 05:04:35 INFO       - processed 300000 van\n",
      "2023-11-11 05:04:37 INFO       - processed 310000 van\n",
      "2023-11-11 05:04:39 INFO       - processed 320000 van\n",
      "2023-11-11 05:04:40 INFO       - processed 330000 van\n",
      "2023-11-11 05:04:42 INFO       - processed 340000 van\n",
      "2023-11-11 05:04:44 INFO       - processed 350000 van\n",
      "2023-11-11 05:04:46 INFO       - processed 360000 van\n",
      "2023-11-11 05:04:48 INFO       - processed 370000 van\n",
      "2023-11-11 05:04:49 INFO       - processed 380000 van\n",
      "2023-11-11 05:04:51 INFO       - processed 390000 van\n"
     ]
    }
   ],
   "source": [
    "for idx,(van, text) in enumerate(van_indexing.items()):\n",
    "    text_list = \"\\n\".join(x[0] for x in text)\n",
    "   # Add data to the table\n",
    "    data = ('1', 'Hello, world!')\n",
    "    cursor.execute('INSERT INTO van_indexing (id, words) VALUES (?, ?)', (van,text_list))\n",
    "    if idx % 10000 == 0:\n",
    "        logging.info(f'  - processed {idx} van')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['scp', '-i', '/home/giangtran/.ssh/giang_key.pem', '/mnt/d/personal_working/bavandangvanba/app_metadata/example.db', 'giangtran@ec2-52-74-160-204.ap-southeast-1.compute.amazonaws.com:/home/giangtran/working/bavandangvanba/app_metadata/example.db'], returncode=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "source_file_path = \"/mnt/d/personal_working/bavandangvanba/app_metadata/example.db\"\n",
    "destination_file_path = \"giangtran@ec2-52-74-160-204.ap-southeast-1.compute.amazonaws.com:/home/giangtran/working/bavandangvanba/app_metadata/example.db\"\n",
    "key_file_path = \"/home/giangtran/.ssh/giang_key.pem\"\n",
    "\n",
    "subprocess.run([\"scp\", \"-i\", key_file_path, source_file_path, destination_file_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
